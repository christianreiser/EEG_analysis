{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "line of thinking\n",
    "documented motivation\n",
    "understand what er are doing\n",
    "\n",
    "\n",
    "proprocess 3 subjects and provide/document the cleaning times / bad channels, document the bad components\n",
    "\n",
    "- Preprocessing Filtering, re-referencening, ICA\n",
    "- Data cleaning: Time, channel and subjects\n",
    "- ERP peak analysis Extract the study-relevant ERP peak subjectwise (e.g. one value per subject) and statistically test them. RQ: On which ERP-peaks do we find major difference between the conditions?\n",
    "- Time Frequency analysis Calculate an induced time-frequency analysis of the main experimental contrast RQ: What oscillations underley our effect of interest?\n",
    "- either:\t- Mass Univariate Use a multiple regression of the main experimental contrast, controlling for reaction time (you need to calculate RT yourself). RQ: When/Where do we find differences between our conditions? Is there an influence of reaction time?\n",
    "\t\tOR\n",
    "\t\t- Decoding analysis Decode the main contrast of the experiment across time RQ: When is information about the conditions in our data available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary and Exploration\n",
    "P300: A visual oddball experiment with a prolonged effect at 300ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import libraries\n",
    "\"\"\"\n",
    "import mne\n",
    "import ccs_eeg_utils\n",
    "from mne_bids import (BIDSPath,read_raw_bids)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os # make dir\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "matplotlib.use('Agg') # silent mode but doesnt work\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filtering(raw, subject_id):\n",
    "    \"\"\"\n",
    "    applys the firwin banpassfilter between 0.1 and 54 hz\n",
    "    \"\"\"\n",
    "    print('filtering ...')\n",
    "\n",
    "    # plot raw data before band-pass filtering\n",
    "    raw.plot_psd(area_mode='range', tmax=10.0, average=False,xscale=\"linear\",)\n",
    "    ccs_eeg_utils.save_plot('01freq_before_filtering',bids_path)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    band-pass filter between 0.1 Hz and 50 Hz, because Acunzo et al., 2012 recommended highp-pass <=1Hz and >40Hz and FIR. 0.75 (mildly) reduces P3 response amplitude\n",
    "    59 to remove power line atifacts which are at 60 Hz\n",
    "    \"\"\"\n",
    "    # apply filter\n",
    "    raw_f = raw.copy().filter(0.1,54, fir_design='firwin')\n",
    "    raw_f.plot_psd(area_mode='range', tmax=10.0, average=False,xscale=\"log\")\n",
    "    ccs_eeg_utils.save_plot('02freq_after_filtering',bids_path)\n",
    "\n",
    "    return raw_f\n",
    "    \"\"\"\n",
    "    The Filter seems to work as intended, as the power decreases at after 54 Hz.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_channel(num_channels, subject_id):\n",
    "    \"\"\"\n",
    "    plot data\n",
    "    \"\"\"\n",
    "    print('plotting each channel ...')\n",
    "    \n",
    "    # create dir to save plots if not existent        \n",
    "    if not os.path.exists(str(str(bids_path)[:-37] + 'results/03whole_overlay/')): \n",
    "        os.makedirs(str(str(bids_path)[:-37] + 'results/03whole_overlay/'))\n",
    "\n",
    "    \n",
    "    # Extract a single channel and plot the whole timeseries.\n",
    "    for channel_number in range(1,num_channels):#1\n",
    "\n",
    "        # show filtered -> low frequencies\n",
    "        fig = plt.figure()\n",
    "        a1 = fig.add_axes([0,0,1,1])\n",
    "        a1.plot((raw[channel_number-1] [0].T))\n",
    "        a1.plot((raw_f[channel_number-1] [0].T))\n",
    "        a1.legend(['raw', 'band-pass filtered'])\n",
    "        plt.title('Subject: '+str(subject_id)+', channel: '+str(channel_number))\n",
    "        plt.ylabel('potential [µV]')\n",
    "        plt.xlabel('sample')\n",
    "        #a1.set_xlim(0,25)\n",
    "        #a1.set_ylim(-0.00003,0.00003)\n",
    "        plt.savefig(str(str(bids_path)[:-37] + 'results/03whole_overlay/channel'+str(channel_number)+'.png'),bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        plt.close(fig) # don't display figure\n",
    "        \n",
    "    # show raw -> high frequnecies\n",
    "    channel_number = 1\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0,0,1,1])\n",
    "    a1.plot((raw[channel_number-1] [0].T))\n",
    "    a1.plot((raw_f[channel_number-1] [0].T))\n",
    "    a1.legend(['raw', 'band-pass filtered'])\n",
    "    plt.title('Subject: '+str(subject_id)+', channel: '+str(channel_number))\n",
    "    plt.ylabel('potential [µV]')\n",
    "    plt.xlabel('sample')\n",
    "    a1.set_xlim(0,25)\n",
    "    a1.set_ylim(0.00294,0.003)\n",
    "    ccs_eeg_utils.save_plot('04zoom_raw',bids_path)\n",
    "    plt.close(fig) # don't display figure\n",
    "\n",
    "    # show filtered -> high frequnecies are filtered\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0,0,1,1])\n",
    "    a1.plot((raw[channel_number-1] [0].T))\n",
    "    a1.plot((raw_f[channel_number-1] [0].T))\n",
    "    a1.legend(['raw', 'band-pass filtered'])\n",
    "    plt.title('Subject: '+str(subject_id)+', channel: '+str(channel_number))\n",
    "    plt.ylabel('potential [µV]')\n",
    "    plt.xlabel('sample')\n",
    "    a1.set_xlim(0,25)\n",
    "    a1.set_ylim(-0.00003,0.00003)\n",
    "    ccs_eeg_utils.save_plot('05zoom_filtered',bids_path)\n",
    "    plt.close(fig) # don't display figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA(raw_f):      \n",
    "    \"\"\"\n",
    "    ICA\n",
    "    \"\"\"\n",
    "    print('running ICA ...')\n",
    "    # set sampling frequency to 2 Hz as suggested on Pipeline slide to speed up ICA calculation\n",
    "    # raw_f.resample(100, npad=\"auto\") # not sure if needed\n",
    "\n",
    "    # Generate an ICA object \n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\", max_iter=400) # didn't converge after default max_iter=200\n",
    "\n",
    "    # fit the ICA on the data\n",
    "    ica.fit(raw_f,verbose=True)\n",
    "\n",
    "    # plot components\n",
    "    ica.plot_components(picks=range(30))    \n",
    "    ccs_eeg_utils.save_plot('06ICA_components', bids_path)\n",
    "\n",
    "    # plot properties\n",
    "    # create dir to save plots if not existent\n",
    "\n",
    "    if not os.path.exists(str(str(bids_path)[:-37] + 'results/07ICA_properties/')): \n",
    "        os.makedirs(str(str(bids_path)[:-37] + 'results/07ICA_properties/'))\n",
    "    for component in range(ica.n_components_):\n",
    "        ica.plot_properties(raw_f,picks=component,psd_args={'fmax': 35.},reject=None)\n",
    "        # save plot    \n",
    "        plt.savefig(str(str(bids_path)[:-37] + 'results/07ICA_properties/component'+str(component)+'.png'),bbox_inches='tight')\n",
    "\n",
    "        # don't display figure\n",
    "        plt.close()\n",
    "    \n",
    "    \"\"\" TODO generalize for all subjects\"\"\"\n",
    "    \"\"\"\n",
    "    # Artefacts of subject one\n",
    "    heartbeat_artefacts = []\n",
    "    blink_artefacts = [3]\n",
    "    eye_artefacts = [0,1,2,6,24,29]\n",
    "    muscle_artefacts = [5,7,10,13,16,18,21,23,28,29] # often non-stationary activity, small ERPs, \"square-root spectrum\", one electrode?, Yaw, below/behind ear, lowwe back of the head, \n",
    "    noisy_electrodes = [] # single active electrode, small ERP, strong 50/60hz line noise\n",
    "    other_artefacts = []\n",
    "    # brain components ideally show strong and clear ERPs, activity stationary over whole experiment, powerspectrum including alpha/beta peak at ~10hz, \n",
    "    \"\"\"\n",
    "    # Artefacts of subject two\n",
    "    heartbeat_artefacts = []\n",
    "    blink_artefacts = [0]\n",
    "    eye_artefacts = []\n",
    "    muscle_artefacts = [12,19,25] # often non-stationary activity, small ERPs, \"square-root spectrum\", one electrode?, Yaw, below/behind ear, lowwe back of the head, \n",
    "    noisy_electrodes = [29] # single active electrode, small ERP, strong 50/60hz line noise\n",
    "    other_artefacts = [3,7,8,22,23]\n",
    "    # brain components ideally show strong and clear ERPs, activity stationary over whole experiment, powerspectrum including alpha/beta peak at ~10hz, \n",
    "\n",
    "    exclude = []\n",
    "    exclude.extend(heartbeat_artefacts)\n",
    "    exclude.extend(blink_artefacts)\n",
    "    exclude.extend(eye_artefacts)\n",
    "    exclude.extend(muscle_artefacts)\n",
    "    exclude.extend(other_artefacts)\n",
    "    print('excluded components:', exclude)\n",
    "    ica.exclude = exclude\n",
    "\n",
    "    # add events\n",
    "    evts, evts_dict_stim= add_events(raw_f)\n",
    "\n",
    "    # before ICA\n",
    "    epochs = mne.Epochs(ica.get_sources(raw_f),evts,evts_dict_stim,tmin=-0.2,tmax=0.8)\n",
    "    epochs.average(picks=13).plot() # 13 for Pz?\n",
    "    ccs_eeg_utils.save_plot('08Pz_before_ICA', bids_path)\n",
    "\n",
    "    # after ICA\n",
    "    epochs = mne.Epochs(raw_f,evts,evts_dict_stim,tmin=-0.2,tmax=0.8)\n",
    "    epochs.average().plot(picks='Pz')\n",
    "    ccs_eeg_utils.save_plot('09Pz_after_ICA', bids_path)\n",
    "\n",
    "    # before / after overlay\n",
    "    reconst_raw_f = raw_f.copy()\n",
    "    ica.apply(reconst_raw_f,exclude=exclude)\n",
    "\n",
    "    #raw_f.plot()\n",
    "    #reconst_raw_f.plot()  \n",
    "    ica.plot_overlay(raw_f,exclude=exclude)\n",
    "    ccs_eeg_utils.save_plot('10before_after_overlay', bids_path)\n",
    "    \n",
    "    # save ICA \n",
    "    ica.save(str(str(bids_path)[:-4] + '_chrei_ica.fif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_events(raw):\n",
    "    \"\"\"\n",
    "    add events\n",
    "    \"\"\"\n",
    "    print('adding events ...')\n",
    "    evts,evts_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # get all keys which contain \"stimulus\"\n",
    "    wanted_keys = [e for e in evts_dict.keys() if \"stimulus\" in e]    # subset the large event-dictionairy\n",
    "    \n",
    "    evts_dict_stim=dict((k, evts_dict[k]) for k in wanted_keys if k in evts_dict)\n",
    "    \n",
    "    return evts,evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching():\n",
    "    # Choosing Pz for P3 because this is the site most widely used in the literature and \n",
    "    # recommended by Kappenman et al.\n",
    "    # Cut the raw data to one channel using `raw.pick_channels([\"Pz\"])` - \n",
    "\n",
    "    evts,evts_dict_stim = add_events(raw)\n",
    "\n",
    "    raw_f.pick_channels([\"Pz\"])\n",
    "    print(raw_f)\n",
    "    plt.plot(raw_f[:,:][0].T)\n",
    "    ccs_eeg_utils.save_plot('11Pz', bids_path)\n",
    "\n",
    "    raw_f.info\n",
    "\n",
    "    # These values reflect the values in the bids `*_events.tsv` file.\n",
    "    raw_f.annotations \n",
    "\n",
    "    # Epoch the data \n",
    "    epochs = mne.Epochs(raw_f,evts,evts_dict_stim,tmin=-0.2,tmax=0.8,baseline=(-0.2,0)) # tmin and tmax chosen as recommended by Kappenman et al.\n",
    "\n",
    "    # Plot all trials\n",
    "    plt.plot(np.squeeze(epochs.get_data()[:,0,:].T))\n",
    "    ccs_eeg_utils.save_plot('12trials', bids_path)\n",
    "\n",
    "    return epochs,evts,evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erp_analysis():\n",
    "    # indexing and averaging epochs\n",
    "    target = epochs[[\"stimulus:{}{}\".format(k,k) for k in [1,2,3,4,5]]].average()\n",
    "    distractor = epochs[[\"stimulus:{}{}\".format(k,j) for k in [1,2,3,4,5] for j in [1,2,3,4,5] if k!=j]].average()\n",
    "\n",
    "    # indexing and averaging epochs\n",
    "    target = epochs[[\"stimulus:{}{}\".format(k,k) for k in [1,2,3,4,5]]].average()\n",
    "    distractor = epochs[[\"stimulus:{}{}\".format(k,j) for k in [1,2,3,4,5] for j in [1,2,3,4,5] if k!=j]].average()\n",
    "\n",
    "    # plotting\n",
    "    mne.viz.plot_compare_evokeds([target,distractor])\n",
    "    ccs_eeg_utils.save_plot('13epochs_average', bids_path)\n",
    "    \n",
    "    return target, distractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject = 2\n",
      "Reading ../local/bids/sub-002/ses-P3/eeg/sub-002_task-P3_eeg.fdt\n",
      "Reading events from ../local/bids/sub-002/ses-P3/eeg/sub-002_ses-P3_task-P3_events.tsv.\n",
      "Reading channel info from ../local/bids/sub-002/ses-P3/eeg/sub-002_ses-P3_task-P3_channels.tsv.\n",
      "Reading 0 ... 414719  =      0.000 ...   404.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f3bf0aec4b23>:24: RuntimeWarning: Did not find any coordsystem.json associated with sub-002_ses-P3_task-P3.\n",
      "\n",
      "The search_str was \"../local/bids/sub-002/**/sub-002_ses-P3*coordsystem.json\"\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "filtering ...\n",
      "Effective window size : 8.000 (s)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 8449 samples (33.004 sec)\n",
      "\n",
      "Effective window size : 8.000 (s)\n",
      "plotting each channel ...\n",
      "running ICA ...\n",
      "Fitting ICA to data using 30 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Selecting all PCA components: 30 components\n",
      "Fitting ICA took 11.5s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "excluded components: [0, 12, 19, 25, 3, 7, 8, 22, 23]\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Need more than one channel to make topography for eeg. Disabling interactivity.\n",
      "Transforming to ICA space (30 components)\n",
      "Zeroing out 9 ICA components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming to ICA space (30 components)\n",
      "Zeroing out 9 ICA components\n",
      "Writing ICA solution to ../local/bids/sub-002/ses-P3/eeg/sub-002_ses-P3_task-P3_events_chrei_ica.fif...\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-002_task-P3_eeg.fdt, 1 x 103680 (405.0 s), ~841 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pipeline\n",
    "\n",
    "load data\n",
    "read annotations\n",
    "resample to 256 Hz\n",
    "re-reference to P9 and P10\n",
    "(Extract a single channel and plot the whole timeseries)\n",
    "\"\"\"\n",
    "# path where to save the datasets.\n",
    "bids_root = \"../local/bids\"\n",
    "num_subjects = 2#37\n",
    "num_channels = 33\n",
    "\n",
    "for subject in range(2,num_subjects+1):\n",
    "    print('subject =',subject)\n",
    "    subject_id = f\"{subject:03}\"\n",
    "\n",
    "    bids_path = BIDSPath(subject=subject_id,task=\"P3\",session=\"P3\",\n",
    "                         datatype='eeg', suffix='eeg',\n",
    "                         root=bids_root)\n",
    "\n",
    "    # read the file\n",
    "    raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # fix the annotations readin\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path,raw)\n",
    "    \n",
    "    # load data\n",
    "    raw.load_data()\n",
    "\n",
    "    # delay shift\n",
    "    # todo\n",
    "   \n",
    "    # resample / downsample frequency\n",
    "    raw.resample(256, npad=\"auto\")  # set sampling frequency to 256 Hz as in Kappenman et al. \n",
    "    \n",
    "    # rerefernecing to P9 and P10 becuase Kappenman et al. says \n",
    "    # \"we find that P9 and P10 provide cleaner signals than the traditional mastoid sites\"\n",
    "    raw.set_eeg_reference(ref_channels=['P9', 'P10'], verbose=None) \n",
    "    \n",
    "    # add channel locations\n",
    "    raw.set_montage('standard_1020',match_case=False)\n",
    "    \n",
    "    # band pass filtering between 0.1 and 54 hz\n",
    "    raw_f = band_pass_filtering(raw, subject_id)\n",
    "    \n",
    "    \n",
    "    # plot each channel\n",
    "    plot_each_channel(num_channels, subject_id) # takes a while\n",
    "\n",
    "    \"\"\"TODO: remove large muscle artifacts, extreme voltage offsets, \n",
    "    or break periods longer than two seconds\"\"\"\n",
    "\n",
    "    # ICA\n",
    "    ICA(raw_f)\n",
    "\n",
    "    epochs,evts,evts_dict_stim = epoching()\n",
    "    \n",
    "    target, distractor = erp_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the unit/scale of the data?\n",
    "**A:** Electric potential in [µV] and time in [ms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T:** Have a look at `raw.info` and note down what the sampling frequency is (how many EEG-samples per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 11 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
       " chs: 30 EEG, 3 EOG\n",
       " custom_ref_applied: True\n",
       " dig: 33 items (3 Cardinal, 30 EEG)\n",
       " highpass: 0.0 Hz\n",
       " line_freq: 60\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 33\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 4 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub-002_task-P3_events.tsv file:\n",
    "\n",
    "| onset   | duration | sample | trial    | stim_file | value |\n",
    "|---------|----------|--------|----------|-----------|-------|\n",
    "| 11.9561 | 0.0      | 12244  | response | n/a       | 202   |\n",
    "| 13.9639 | 0.0      | 14300  | response | n/a       | 202   |\n",
    "| 18.3779 | 0.2      | 18820  | stimulus | n/a       | 45    |\n",
    "| ...     | ...      | ...    | ...      | ...       | ...   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-002_task-P3_eeg.fdt, 1 x 103680 (405.0 s), ~841 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs,evts,evts_dict_stim = epoching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 100 epochs: 0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 25, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 55, 56, 58, 64, 65, 66, 67, 72, 83, 87, 92, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 114, 115, 116, 117, 118, 119, 134, 137, 138, 139, 140, 142, 144, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199\n"
     ]
    }
   ],
   "source": [
    "# ensure all conditions have the same counts, as the ANOVA expects a fully balanced data matrix and \n",
    "# does not forgive imbalances that generously (risk of type-I error).\n",
    "epochs.equalize_event_counts(evts_dict_stim) # TODO not sure if it's good that 100 epoches are droped\n",
    "\n",
    "# Factor to down-sample the temporal dimension of the TFR computed by\n",
    "# tfr_morlet.\n",
    "decim = 2\n",
    "frequencies = np.arange(7, 30, 3)  # define frequencies of interest\n",
    "n_cycles = frequencies / frequencies[0]\n",
    "zero_mean = False  # don't correct morlet wavelet to be of mean zero\n",
    "# To have a true wavelet zero_mean should be True but here for illustration\n",
    "# purposes it helps to spot the evoked response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import f_threshold_mway_rm, f_mway_rm, fdr_correction\n",
    "from mne.datasets import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n",
      "Loading data for 4 events and 257 original time points ...\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: ratio)\n"
     ]
    }
   ],
   "source": [
    "# Create TFR (time-frequency representations) for all conditions\n",
    "epochs_power = list()\n",
    "for condition in [epochs[k] for k in evts_dict_stim]:\n",
    "    this_tfr = tfr_morlet(condition, frequencies, n_cycles=n_cycles,\n",
    "                          decim=decim, average=False, zero_mean=zero_mean,\n",
    "                          return_itc=False)\n",
    "    this_tfr.apply_baseline(mode='ratio', baseline=(None, 0))\n",
    "    this_power = this_tfr.data[:, 0, :, :]  # we only have one channel.\n",
    "    epochs_power.append(this_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup repeated measures ANOVA\n",
    "# We will tell the ANOVA how to interpret the data matrix in terms of factors. \n",
    "# This is done via the factor levels argument which is a list of the number factor levels for each factor.\n",
    "n_conditions = len(epochs.event_id)\n",
    "n_replications = int(epochs.events.shape[0] / n_conditions)\n",
    "\n",
    "factor_levels = [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]  # number of levels in each factor\n",
    "effects = 'A*B'  # this is the default signature for computing all effects\n",
    "# Other possible options are 'A' or 'B' for the corresponding main effects\n",
    "# or 'A:B' for the interaction effect only (this notation is borrowed from the\n",
    "# R formula language)\n",
    "n_frequencies = len(frequencies)\n",
    "times = 1e3 * epochs.times[::decim]\n",
    "n_times = len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1032)\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Now we’ll assemble the data matrix and swap axes so the trial replications are the first dimension and the conditions are the second dimension.\n",
    "\n",
    "data = np.swapaxes(np.asarray(epochs_power), 1, 0)\n",
    "# reshape last two dimensions in one mass-univariate observation-vector\n",
    "data = data.reshape(n_replications, n_conditions, n_frequencies * n_times)\n",
    "\n",
    "# so we have replications * conditions * observations:\n",
    "print(data.shape)\n",
    "print(n_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_mway_rm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bde4d87473df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# despite the ‘induced’ approach. For analysis for induced power at the group level averaged TRFs are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f_mway_rm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_mway_rm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0meffect_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'modality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modality by location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/mne/stats/parametric.py\u001b[0m in \u001b[0;36mf_mway_rm\u001b[0;34m(data, factor_levels, effects, correction, return_pvals)\u001b[0m\n\u001b[1;32m    387\u001b[0m             data.shape[0], data.shape[1], np.prod(data.shape[2:]))\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0meffect_picks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_effects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mn_replications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/mne/stats/parametric.py\u001b[0m in \u001b[0;36m_map_effects\u001b[0;34m(n_factors, effects)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthis_effect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mcontrast_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_contrast_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_effect\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mthis_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_factors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mthis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfactor_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis_code\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/mne/stats/parametric.py\u001b[0m in \u001b[0;36m_get_contrast_indices\u001b[0;34m(effect_idx, n_factors)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;34m\"\"\"Henson's factor coding, see num2binvec.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mbinrepr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffect_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbinrepr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/mne/stats/parametric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;34m\"\"\"Henson's factor coding, see num2binvec.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mbinrepr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffect_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbinrepr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now we’re ready to run our repeated measures ANOVA.\n",
    "\n",
    "# Note. As we treat trials as subjects, the test only accounts for time locked responses,\n",
    "# despite the ‘induced’ approach. For analysis for induced power at the group level averaged TRFs are required.\n",
    "print('f_mway_rm')\n",
    "fvals, pvals = f_mway_rm(data, factor_levels, effects=effects)\n",
    "\n",
    "effect_labels = ['modality', 'location', 'modality by location']\n",
    "\n",
    "# let's visualize our effects by computing f-images\n",
    "for effect, sig, effect_label in zip(fvals, pvals, effect_labels):\n",
    "    print('for')\n",
    "    plt.figure()\n",
    "    # show naive F-values in gray\n",
    "    plt.imshow(effect.reshape(8, 211), cmap=plt.cm.gray, extent=[times[0],\n",
    "               times[-1], frequencies[0], frequencies[-1]], aspect='auto',\n",
    "               origin='lower')\n",
    "    # create mask for significant Time-frequency locations\n",
    "    effect = np.ma.masked_array(effect, [sig > .05])\n",
    "    plt.imshow(effect.reshape(8, 211), cmap='RdBu_r', extent=[times[0],\n",
    "               times[-1], frequencies[0], frequencies[-1]], aspect='auto',\n",
    "               origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title(r\"Time-locked response for '%s' (%s)\" % (effect_label, ch_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "exercise 3 but is it necessary?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
