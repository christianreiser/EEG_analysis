{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "line of thinking\n",
    "documented motivation\n",
    "understand what er are doing\n",
    "\n",
    "\n",
    "proprocess 3 subjects and provide/document the cleaning times / bad channels, document the bad components\n",
    "\n",
    "- Preprocessing Filtering, re-referencening, ICA\n",
    "- Data cleaning: Time, channel and subjects\n",
    "- ERP peak analysis Extract the study-relevant ERP peak subjectwise (e.g. one value per subject) and statistically test them. RQ: On which ERP-peaks do we find major difference between the conditions?\n",
    "- Time Frequency analysis Calculate an induced time-frequency analysis of the main experimental contrast RQ: What oscillations underley our effect of interest?\n",
    "- either:\t- Mass Univariate Use a multiple regression of the main experimental contrast, controlling for reaction time (you need to calculate RT yourself). RQ: When/Where do we find differences between our conditions? Is there an influence of reaction time?\n",
    "\t\tOR\n",
    "\t\t- Decoding analysis Decode the main contrast of the experiment across time RQ: When is information about the conditions in our data available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary and Exploration\n",
    "P300: A visual oddball experiment with a prolonged effect at 300ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import libraries\n",
    "\"\"\"\n",
    "import mne\n",
    "import ccs_eeg_utils\n",
    "from mne.channels import compute_native_head_t, read_custom_montage\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne.viz import plot_alignment\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "#%matplotlib inline\n",
    "import os  # make dir\n",
    "import os.path as op\n",
    "from config import *\n",
    "import numpy as np\n",
    "from pyvistaqt import BackgroundPlotter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample():\n",
    "    print('before resampling:', raw.info)\n",
    "    raw.resample(\n",
    "        sfreq, npad=\"auto\"\n",
    "    )  # set sampling frequency to 256 Hz as in Kappenman et al.\n",
    "    print('after resampling:', raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereference():\n",
    "    # rerefernecing to P9 and P10 becuase Kappenman et al. says\n",
    "    # \"we find that P9 and P10 provide cleaner signals than the traditional mastoid sites\"\n",
    "    raw.plot(n_channels=len(raw.ch_names), duration = 5, start = 18)\n",
    "    ccs_eeg_utils.save_plot(\"000beforeRereferencing\", bids_path)\n",
    "    raw.set_eeg_reference(ref_channels=ref_channels, verbose=None)\n",
    "    raw.plot(n_channels=len(raw.ch_names), duration = 5, start = 18)\n",
    "    ccs_eeg_utils.save_plot(\"000rereferencedToP9P10\", bids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_montage():\n",
    "    # Set EEG sensor configuration and head digitization\n",
    "    raw.set_montage(\"standard_1020\", match_case=False)\n",
    "    raw.plot_sensors(ch_type='eeg')\n",
    "    ccs_eeg_utils.save_plot(\"00montage\", bids_path)    \n",
    "    print(raw.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filtering(subject_id):\n",
    "    \"\"\"\n",
    "    applys the firwin banpassfilter\n",
    "    \"\"\"\n",
    "    print(\"filtering ...\")\n",
    "\n",
    "    # plot raw data before band-pass filtering\n",
    "    raw.plot_psd(\n",
    "        area_mode=\"range\",\n",
    "        tmax=10.0,\n",
    "        average=False,\n",
    "        xscale=\"linear\",\n",
    "    )\n",
    "    ccs_eeg_utils.save_plot(\"01freq_before_filtering\", bids_path)\n",
    "\n",
    "    # apply filter\n",
    "    raw_f = raw.copy().filter(l_freq, h_freq, fir_design=fir_design)\n",
    "    raw_f.plot_psd(area_mode=\"range\", tmax=10.0, average=False, xscale=\"log\")\n",
    "    ccs_eeg_utils.save_plot(\"02freq_after_filtering\", bids_path)\n",
    "    \n",
    "    return raw_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_channel(subject_id):\n",
    "    \"\"\"\n",
    "    plot data\n",
    "    \"\"\"\n",
    "    print(\"plotting each channel ...\")\n",
    "\n",
    "    # create dir to save plots if not existent\n",
    "    if not os.path.exists(str(\"./../results/\" + str(bids_path)[14:-37]) + str(\"03whole_overlay/\")):\n",
    "        os.makedirs(\n",
    "            str(\"./../results/\" + str(bids_path)[14:-37]) + str(\"03whole_overlay/\")\n",
    "        )\n",
    "\n",
    "    # Extract a single channel and plot the whole timeseries.\n",
    "    for channel_number in range(1, len(raw.ch_names)):  # 1\n",
    "\n",
    "        # show filtered -> low frequencies\n",
    "        fig = plt.figure()\n",
    "        a1 = fig.add_axes([0, 0, 1, 1])\n",
    "        a1.plot((raw[channel_number - 1][0].T))\n",
    "        a1.plot((raw_f[channel_number - 1][0].T))\n",
    "        a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "        plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "        plt.ylabel(\"potential [µV]\")\n",
    "        plt.xlabel(\"sample\")\n",
    "        # a1.set_xlim(0,25)\n",
    "        # a1.set_ylim(-0.00003,0.00003)\n",
    "        plt.savefig(\n",
    "            str(\"./../results/\" + str(bids_path)[14:-37])\n",
    "            + str(\"03whole_overlay/channel\" + str(channel_number) + \".png\"),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        # plt.show()\n",
    "        plt.close()  # don't display figure\n",
    "\n",
    "    # show raw -> high frequnecies\n",
    "    channel_number = 1\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0, 0, 1, 1])\n",
    "    a1.plot((raw[channel_number - 1][0].T))\n",
    "    a1.plot((raw_f[channel_number - 1][0].T))\n",
    "    a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "    plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "    plt.ylabel(\"potential [µV]\")\n",
    "    plt.xlabel(\"sample\")\n",
    "    a1.set_xlim(0, 25)\n",
    "    a1.set_ylim(0.0199, 0.01993)\n",
    "    ccs_eeg_utils.save_plot(\"04zoom_raw\", bids_path)\n",
    "    plt.close()  # don't display figure\n",
    "\n",
    "    # show filtered -> high frequnecies are filtered\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0, 0, 1, 1])\n",
    "    a1.plot((raw[channel_number - 1][0].T))\n",
    "    a1.plot((raw_f[channel_number - 1][0].T))\n",
    "    a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "    plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "    plt.ylabel(\"potential [µV]\")\n",
    "    plt.xlabel(\"sample\")\n",
    "    a1.set_xlim(0, 25)\n",
    "    a1.set_ylim(-0.00001, 0.00002)\n",
    "    ccs_eeg_utils.save_plot(\"05zoom_filtered\", bids_path)\n",
    "    plt.close()  # don't display figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(raw_f,subject):\n",
    "    \"\"\"\n",
    "    TODO clean and plot\n",
    "    \"\"\"\n",
    "    # read bad annotations\n",
    "    filename = str(\"./../results/\" + str(bids_path)[14:-37]) + str(\n",
    "        \"badannotations\" + \".csv\"\n",
    "    )\n",
    "\n",
    "    # read annotations\n",
    "    if subject == 1 or 2 or 3:\n",
    "        annotations = mne.read_annotations(filename)\n",
    "\n",
    "        # append bad annotations\n",
    "        raw_f.annotations.append(\n",
    "            annotations.onset, annotations.duration, annotations.description\n",
    "        )  # duplicates\n",
    "\n",
    "    # clean manually\n",
    "    %matplotlib qt\n",
    "    duration = [5, 5, 10]  # duration for plot\n",
    "    start = [209, 231, 95]  # start time for plot\n",
    "    raw_f.plot(\n",
    "        n_channels=len(raw_f.ch_names),\n",
    "        duration=duration[subject - 1],\n",
    "        start=start[subject - 1],\n",
    "    )  # interactive plot\n",
    "    if closeInteractiveCleaningPlot:\n",
    "        ccs_eeg_utils.save_plot(\"050cleaning_data\", bids_path)\n",
    "\n",
    "    # To modify annotations, use plot and run next two functions of getting and saving annotations\n",
    "    # get bad annotations\n",
    "    \"\"\"bad_ix = [\n",
    "        i for i, a in enumerate(raw_f.annotations) if a[\"description\"] == \"BAD_\"\n",
    "    ]\n",
    "    \n",
    "    # save bad annotations\n",
    "    raw_f.annotations[bad_ix].save(\n",
    "        str('./../results/' + str(bids_path)[14:-37])+str(\"badannotations\"\n",
    "            + \".csv\"\n",
    "        )\n",
    "    )\"\"\"\n",
    "\n",
    "    # remove bad channels\n",
    "    raw_f.info[\"bads\"] = []\n",
    "\n",
    "    # intepolate bad channels\n",
    "    # raw_f.interpolate_bads()  # no bad channel found\n",
    "\n",
    "    # save cleaned data\n",
    "    raw_f.save(\n",
    "        str(\"./../results/\" + str(bids_path)[14:-37]) + str(\"after_cleaning_raw.fif\"),\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # load cleaned data\n",
    "    # raw_cleaned = mne.io.read_raw_fif(str('./../results/' + str(bids_path)[14:-37])+str(\"after_cleaning_raw.fif\"))\n",
    "\n",
    "    # visualize effect of cleaning on ERP\n",
    "    evts, evts_dict = mne.events_from_annotations(raw)\n",
    "    wanted_keys = [e for e in evts_dict.keys() if \"stimulus\" in e]\n",
    "    evts_dict_stim = dict((k, evts_dict[k]) for k in wanted_keys if k in evts_dict)\n",
    "\n",
    "    # get raw epochs without rejections\n",
    "    epochs = mne.Epochs(\n",
    "        raw_f,\n",
    "        evts,\n",
    "        evts_dict_stim,\n",
    "        tmin=epoch_tmin,\n",
    "        tmax=epoch_tmax,\n",
    "        reject_by_annotation=False,\n",
    "    )\n",
    "\n",
    "    # get epochs with manual rejection\n",
    "    epochs_manual = mne.Epochs(\n",
    "        raw_f,\n",
    "        evts,\n",
    "        evts_dict_stim,\n",
    "        tmin=epoch_tmin,\n",
    "        tmax=epoch_tmax,\n",
    "        reject_by_annotation=True,\n",
    "    )\n",
    "\n",
    "    # get epochs with threshold rejection\n",
    "    reject_criteria = dict(\n",
    "        eeg=rejection_threshold,\n",
    "        eog=rejection_threshold,\n",
    "    )\n",
    "    epochs_thresh = mne.Epochs(\n",
    "        raw_f,\n",
    "        evts,\n",
    "        evts_dict_stim,\n",
    "        tmin=epoch_tmin,\n",
    "        tmax=epoch_tmax,\n",
    "        reject=reject_criteria,\n",
    "        reject_by_annotation=False,\n",
    "    )\n",
    "\n",
    "    # get epochs with Manual + theshold rejection\n",
    "    epochs__manual_and_thresh = mne.Epochs(\n",
    "        raw_f,\n",
    "        evts,\n",
    "        evts_dict_stim,\n",
    "        tmin=epoch_tmin,\n",
    "        tmax=epoch_tmax,\n",
    "        reject=reject_criteria,\n",
    "        reject_by_annotation=True,\n",
    "    )\n",
    "\n",
    "    # plot comparison\n",
    "    mne.viz.plot_compare_evokeds(\n",
    "        {\n",
    "            \"raw\": epochs.average(),\n",
    "            \"manual\": epochs_manual.average(),\n",
    "            \"thresh\": epochs_thresh.average(),\n",
    "            \"both\": epochs__manual_and_thresh.average(),\n",
    "        },\n",
    "        picks=picked_channel,\n",
    "    )\n",
    "    \n",
    "    # save amd close plot\n",
    "    ccs_eeg_utils.save_plot(\"05cleaning_compare_evoked\", bids_path)\n",
    "    \n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_events(raw):\n",
    "    \"\"\"\n",
    "    add events\n",
    "    \"\"\"\n",
    "    print(\"adding events ...\")\n",
    "    evts, evts_dict = mne.events_from_annotations(raw_f)\n",
    "\n",
    "    # get all keys which contain \"stimulus\"\n",
    "    wanted_keys = [\n",
    "        e for e in evts_dict.keys() if \"stimulus\" in e\n",
    "    ]  # subset the large event-dictionairy\n",
    "\n",
    "    evts_dict_stim = dict((k, evts_dict[k]) for k in wanted_keys if k in evts_dict)\n",
    "\n",
    "    return evts, evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA(raw_f_f, subject):\n",
    "    \"\"\"\n",
    "    ICA\n",
    "    \"\"\"\n",
    "    print(\"running ICA ...\")\n",
    "    # apply a high pass filter of 1.5 Hz\n",
    "    raw_f_f = raw_f.copy()\n",
    "    raw_f_f.filter(l_freq_ica, h_freq_ica, fir_design=fir_design_ica)\n",
    "    \n",
    "        # Generate an ICA object with fixed random state to make it deterministic, thus reproducible\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=0.9999999, random_state=93, method=ica_method, max_iter=200\n",
    "    )\n",
    "\n",
    "    # fit the ICA on the data, where the 1.5Hz high pass filter was applied.\n",
    "    # Also omit bad segments(manual cleaning annotations) from the data before fitting.\n",
    "    ica.fit(raw_f_f, reject_by_annotation=True, verbose=True)\n",
    "\n",
    "    \"\"\"# plot components TODO back on\n",
    "    ica.plot_components(picks=range(ica.n_components_ - 1))\n",
    "    ccs_eeg_utils.save_plot(\"06ICA_components\", bids_path)\n",
    "\n",
    "    # plot properties\n",
    "    # create dir to save plots if not existent\n",
    "    if not os.path.exists(\n",
    "        str(\"./../results/\" + str(bids_path)[14:-37]) + str(\"07ICA_properties/\")\n",
    "    ):\n",
    "        os.makedirs(\n",
    "            str(\"./../results/\" + str(bids_path)[14:-37]) + str(\"07ICA_properties/\")\n",
    "        )\n",
    "    for component in range(ica.n_components_):\n",
    "        ica.plot_properties(\n",
    "            raw_f, picks=component, psd_args={\"fmax\": 35.0}, reject=None\n",
    "        )\n",
    "        # save plot\n",
    "        plt.savefig(\n",
    "            str(\"./../results/\" + str(bids_path)[14:-37])\n",
    "            + str(\"07ICA_properties/component\" + str(component) + \".png\"),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        # don't display figure\n",
    "        plt.close()\"\"\"\n",
    "\n",
    "    # Get artefacts of each subject\n",
    "    if subject == 1:\n",
    "        heartbeat_artefacts = heart_sub1\n",
    "        blink_artefacts = blink_sub1\n",
    "        eye_artefacts = eye_sub1\n",
    "        muscle_artefacts = muscle_sub1  # often non-stationary activity, small ERPs, \"square-root spectrum\", one electrode?, Yaw, below/behind ear, lowwe back of the head,\n",
    "        noisy_electrodes = noisy_electrode_sub1  # single active electrode, small ERP, strong 50/60hz line noise\n",
    "        other_artefacts = other_sub1\n",
    "        unsure_artefacts = unsure_sub1\n",
    "        # brain components ideally show strong and clear ERPs, activity stationary over whole experiment, powerspectrum including alpha/beta peak at ~10hz,\n",
    "\n",
    "    elif subject == 2:\n",
    "        heartbeat_artefacts = heart_sub2\n",
    "        blink_artefacts = blink_sub2\n",
    "        eye_artefacts = eye_sub2\n",
    "        muscle_artefacts = muscle_sub2\n",
    "        noisy_electrodes = noisy_electrode_sub2\n",
    "        other_artefacts = other_sub2\n",
    "        unsure_artefacts = unsure_sub2\n",
    "\n",
    "    elif subject == 3:\n",
    "        heartbeat_artefacts = heart_sub3\n",
    "        blink_artefacts = blink_sub3\n",
    "        eye_artefacts = eye_sub3\n",
    "        muscle_artefacts = muscle_sub3\n",
    "        noisy_electrodes = noisy_electrode_sub3\n",
    "        other_artefacts = other_sub3\n",
    "        unsure_artefacts = unsure_sub3\n",
    "\n",
    "    # exclude artefacts\n",
    "    exclude = []\n",
    "    exclude.extend(heartbeat_artefacts)\n",
    "    exclude.extend(blink_artefacts)\n",
    "    exclude.extend(eye_artefacts)\n",
    "    exclude.extend(muscle_artefacts)\n",
    "    exclude.extend(other_artefacts)\n",
    "    exclude.extend(unsure_artefacts)  #TODO deide if in or out\n",
    "    print(\"excluded components:\", exclude)\n",
    "    ica.exclude = exclude\n",
    "\n",
    "    # add events\n",
    "    evts, evts_dict_stim = add_events(raw_f)\n",
    "\n",
    "    # plot before ICA\n",
    "    epochs = mne.Epochs(raw_f, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax)\n",
    "    epochs.average().plot(picks=picked_channel)\n",
    "    ccs_eeg_utils.save_plot(\"08\" + str(picked_channel) + \"_before_ICA\", bids_path)\n",
    "\n",
    "    # before / after overlay\n",
    "    reconst_raw_f = raw_f.copy()\n",
    "    ica.apply(reconst_raw_f, exclude=exclude)\n",
    "\n",
    "    # plot after ICA\n",
    "    epochs = mne.Epochs(reconst_raw_f, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax)\n",
    "    epochs.average(picks=picked_channel).plot()  # 13 for Pz?\n",
    "    ccs_eeg_utils.save_plot(\"09\" + str(picked_channel) + \"_after_ICA\", bids_path)\n",
    "    print(epochs.info)\n",
    "\n",
    "    # raw_f.plot()\n",
    "    # reconst_raw_f.plot()\n",
    "    ica.plot_overlay(raw_f, exclude=exclude,picks='eeg')\n",
    "    ccs_eeg_utils.save_plot(\"10before_after_overlay\", bids_path)\n",
    "\n",
    "    # save ICA\n",
    "    ica.save(str(str(bids_path)[:-4] + \"_chrei-ica.fif\"))\n",
    "     \n",
    "    return reconst_raw_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching():\n",
    "    # Choosing Pz for P3 because this is the site most widely used in the literature and\n",
    "    # recommended by Kappenman et al.\n",
    "    # Cut the raw_f data to one channel using `raw_f.pick_channels([\"Pz\"])` -\n",
    "\n",
    "    evts, evts_dict_stim = add_events(raw_f)\n",
    "\n",
    "    raw_f.pick_channels([picked_channel])\n",
    "    print(raw_f)\n",
    "    plt.plot(raw_f[:, :][0].T)\n",
    "    ccs_eeg_utils.save_plot(\"11\" + str(picked_channel), bids_path)\n",
    "\n",
    "    raw_f.info\n",
    "\n",
    "    # These values reflect the values in the bids `*_events.tsv` file.\n",
    "    raw_f.annotations\n",
    "\n",
    "    # Epoch the data\n",
    "    epochs = mne.Epochs(\n",
    "        raw_f, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax, baseline=baseline\n",
    "    )  # tmin and tmax chosen as recommended by Kappenman et al.\n",
    "\n",
    "    # Plot all trials\n",
    "    plt.plot(np.squeeze(epochs.get_data()[:, 0, :].T))\n",
    "    ccs_eeg_utils.save_plot(\"12epochs\", bids_path)\n",
    "    \n",
    "    # delay shift\n",
    "    # https://mne.tools/stable/generated/mne.Epochs.html?highlight=delay%20shift\n",
    "    # todo\n",
    "    #epochs.load_data()\n",
    "    #epochs.shift_time(0.026, relative=True)  # for LCD delay: as in Kappenman et al.\n",
    "\n",
    "    # Plot all trials\n",
    "    plt.plot(np.squeeze(epochs.get_data()[:, 0, :].T))\n",
    "    ccs_eeg_utils.save_plot(\"12epochs_after_shift_time\", bids_path)\n",
    "\n",
    "    return epochs, evts, evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_value(data, timestamp):\n",
    "    \"\"\"\n",
    "    get peak values from timestamp\n",
    "    \"\"\"\n",
    "    peak_time_index = data.time_as_index(timestamp)\n",
    "    data_frame = data.to_data_frame(picks=picked_channel)\n",
    "    peak_value = data_frame.at[peak_time_index[0], picked_channel]\n",
    "\n",
    "    return peak_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_peak_data(target_peak, distractor_peak):\n",
    "    \"\"\"\n",
    "    create array where first column is the data and second column is the label\n",
    "    where: target -> 1, distractor -> 0\n",
    "\n",
    "    peak value | label\n",
    "    -----------|------\n",
    "    0.1234     | 1\n",
    "    0.2345     | 0\n",
    "    \"\"\"\n",
    "\n",
    "    # ini matrix with zeros\n",
    "    erp_data = np.zeros(((last_subject) * 2, 2))\n",
    "\n",
    "    # fill targets\n",
    "    for row in range(last_subject):\n",
    "        erp_data[row][0] = target_peak[row]  # values\n",
    "        erp_data[row][1] = 1  # labels\n",
    "\n",
    "    # fill distractors\n",
    "    for row in range(last_subject):\n",
    "        erp_data[row + last_subject][0] = distractor_peak[row]\n",
    "        # erp_data[row+last_subject][1] = 0 # already 0s\n",
    "\n",
    "    print(\"erp_data:\\n\", erp_data)\n",
    "    print(\"erp_data.shape:\", erp_data.shape)\n",
    "\n",
    "    return erp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erp_analysis():\n",
    "    # indexing and averaging epochs\n",
    "    target = epochs[[\"stimulus:{}{}\".format(k, k) for k in [1, 2, 3, 4, 5]]].average()\n",
    "    distractor = epochs[\n",
    "        [\n",
    "            \"stimulus:{}{}\".format(k, j)\n",
    "            for k in [1, 2, 3, 4, 5]\n",
    "            for j in [1, 2, 3, 4, 5]\n",
    "            if k != j\n",
    "        ]\n",
    "    ].average()\n",
    "\n",
    "    # plotting\n",
    "    mne.viz.plot_compare_evokeds([target, distractor])\n",
    "    ccs_eeg_utils.save_plot(\"13epochs_average\", bids_path)\n",
    "\n",
    "    \"\"\"\n",
    "    get peaks\n",
    "    \"\"\"\n",
    "    # get peak times target\n",
    "    _, peak_time_target = target.get_peak(mode=\"pos\")  # get peak time\n",
    "    print(\"peak_time_target:\", peak_time_target)\n",
    "    peak_time_target_list.append(peak_time_target)\n",
    "\n",
    "    # get peak value target\n",
    "    peak_value_target = get_peak_value(target, peak_time_target)\n",
    "    print(\"peak_value_target:\", peak_value_target)\n",
    "    peak_value_target_list.append(peak_value_target)  # from epoch to evoked\n",
    "\n",
    "    # get peak times distractor\n",
    "    _, peak_time_distractor = distractor.get_peak(mode=\"pos\")\n",
    "    print(\"peak_time_distractor:\", peak_time_distractor)\n",
    "    peak_time_distractor_list.append(peak_time_distractor)\n",
    "\n",
    "    # get peak value distractor\n",
    "    peak_value_distractor = get_peak_value(distractor, peak_time_distractor)\n",
    "    print(\"peak_value_distractor:\", peak_value_distractor)\n",
    "    peak_value_distractor_list.append(peak_value_distractor)\n",
    "\n",
    "    # print(target_peak_t,distractor_peak_t)\n",
    "\n",
    "    return (\n",
    "        peak_time_target_list,\n",
    "        peak_value_target_list,\n",
    "        peak_time_distractor_list,\n",
    "        peak_value_distractor_list,\n",
    "        target,\n",
    "        distractor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erp_differences(\n",
    "    peak_target_list,\n",
    "    peak_distractor_list,\n",
    "    title=\"title\",\n",
    "    xlabel=\"xlabel\",\n",
    "    ylabel=\"# subjects\",\n",
    "):\n",
    "    peak_difference_list = np.subtract(peak_target_list, peak_distractor_list)\n",
    "    #%matplotlib inline\n",
    "    _ = plt.hist(\n",
    "        peak_difference_list, bins=\"auto\"\n",
    "    )  # arguments are passed to np.histogram\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    #plt.show()\n",
    "    \n",
    "    # save fig\n",
    "    plt.savefig(\n",
    "        \"../intersubject_results/\"+str(title)+\".png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    # plt.show()\n",
    "    plt.close()  # don't display figure    \n",
    "\n",
    "    average_difference = np.average(peak_difference_list)\n",
    "    meadian_difference = np.median(peak_difference_list)\n",
    "    std_dev_difference = np.std(peak_difference_list)\n",
    "\n",
    "    # print(average_difference, meadian_difference, std_dev_difference)\n",
    "    return average_difference, meadian_difference, std_dev_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(peak_target, peak_distractor):\n",
    "    # create one data array with peak values and labels\n",
    "    peak_data = create_peak_data(peak_target, peak_distractor)\n",
    "\n",
    "    # perform permutation test\n",
    "    t_obs, p_values, H0 = mne.stats.permutation_t_test(peak_data, verbose=True)\n",
    "    # print('t_obs:', t_obs)\n",
    "    # print('p_values:', p_values)\n",
    "    # print('H0:', H0)\n",
    "\n",
    "    return t_obs, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_space_localization():\n",
    "    \"\"\"\n",
    "    TODO check if raw_f needed, but here raw because raw_f has only Pz channel\n",
    "    TODO Source reconstruction without an individual T1 MRI from the subject will be less accurate. Do not over interpret activity locations which can be off by multiple centimeters.\n",
    "    \"\"\"\n",
    "    # set eeg reference because EEG average reference is mandatory for inverse modeling\n",
    "    raw.set_eeg_reference(projection=True)\n",
    "\n",
    "    # get epochs\n",
    "    epochs = mne.Epochs(\n",
    "        raw, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax, baseline=baseline\n",
    "    )\n",
    "\n",
    "    # get evoked\n",
    "    target = epochs[[\"stimulus:{}{}\".format(k, k) for k in [1, 2, 3, 4, 5]]].average()\n",
    "    distractor = epochs[\n",
    "        [\n",
    "            \"stimulus:{}{}\".format(k, j)\n",
    "            for k in [1, 2, 3, 4, 5]\n",
    "            for j in [1, 2, 3, 4, 5]\n",
    "            if k != j\n",
    "        ]\n",
    "    ].average()\n",
    "\n",
    "    \"\"\" TODO also for distractors?\"\"\"\n",
    "    evoked = target\n",
    "    %matplotlib inline\n",
    "    evoked.plot_joint()\n",
    "\n",
    "    # get average src and bem as shown in the following tutorial:\n",
    "    # https://mne.tools/stable/auto_tutorials/source-modeling/plot_eeg_no_mri.html\n",
    "    fs_dir = fetch_fsaverage(verbose=True)\n",
    "    subjects_dir = op.dirname(fs_dir)\n",
    "    subject = \"fsaverage\"\n",
    "    trans = \"fsaverage\"  # MNE has a built-in fsaverage transformation\n",
    "    src = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "    bem = op.join(fs_dir, \"bem\", \"fsaverage-5120-5120-5120-bem-sol.fif\")\n",
    "\n",
    "    # plot to check alignment\n",
    "    \"\"\"TODO why misaligned?\"\"\"\n",
    "    fig = plot_alignment(\n",
    "        evoked.info,\n",
    "        trans=None,\n",
    "        show_axes=True,\n",
    "        surfaces=\"head-dense\",\n",
    "        subject=subject,\n",
    "        subjects_dir=subjects_dir,\n",
    "    )\n",
    "\n",
    "    # Calculate a forward solution for a subject\n",
    "    fwd = mne.make_forward_solution(\n",
    "        evoked.info, trans=None, src=src, bem=bem, verbose=True\n",
    "    )\n",
    "\n",
    "    # Estimate noise covariance matrix from epochs.\n",
    "    cov = mne.compute_covariance(epochs, tmax=0.0)\n",
    "\n",
    "    # Assemble inverse operator\n",
    "    inv = mne.minimum_norm.make_inverse_operator(evoked.info, fwd, cov, verbose=True)\n",
    "\n",
    "    # Apply inverse operator to evoked data.\n",
    "    stc = mne.minimum_norm.apply_inverse(evoked, inv)\n",
    "\n",
    "    # plot source space\n",
    "    %matplotlib inline\n",
    "    brain = stc.plot(subjects_dir=subjects_dir, initial_time=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject = 1\n",
      "Reading ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_eeg.fdt\n",
      "Reading events from ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_events.tsv.\n",
      "Reading channel info from ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_channels.tsv.\n",
      "Reading 0 ... 478207  =      0.000 ...   466.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-5730b31e9299>:34: RuntimeWarning: Data file name in EEG.data (sub-001_task-P3_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-P3_task-P3_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-17-5730b31e9299>:34: RuntimeWarning: Did not find any coordsystem.json associated with sub-001_ses-P3_task-P3.\n",
      "\n",
      "The search_str was \"../local/bids/sub-001/**/sub-001_ses-P3*coordsystem.json\"\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before resampling: <Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
      " chs: 30 EEG, 3 EOG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " line_freq: 60\n",
      " lowpass: 512.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 33\n",
      " projs: []\n",
      " sfreq: 1024.0 Hz\n",
      " subject_info: 4 items (dict)\n",
      ">\n",
      "after resampling: <Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
      " chs: 30 EEG, 3 EOG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " line_freq: 60\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 33\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      " subject_info: 4 items (dict)\n",
      ">\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "<Info | 11 non-empty values\n",
      " bads: []\n",
      " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
      " chs: 30 EEG, 3 EOG\n",
      " custom_ref_applied: True\n",
      " dig: 33 items (3 Cardinal, 30 EEG)\n",
      " highpass: 0.0 Hz\n",
      " line_freq: 60\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 33\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      " subject_info: 4 items (dict)\n",
      ">\n",
      "filtering ...\n",
      "Effective window size : 8.000 (s)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.4 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.40\n",
      "- Lower transition bandwidth: 0.40 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 2113 samples (8.254 sec)\n",
      "\n",
      "Effective window size : 8.000 (s)\n",
      "Overwriting existing file.\n",
      "Writing /home/chrei/code/EEG_analysis/results/sub-001/ses-P3/after_cleaning_raw.fif\n",
      "Closing /home/chrei/code/EEG_analysis/results/sub-001/ses-P3/after_cleaning_raw.fif\n",
      "[done]\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "    Rejecting  epoch based on EEG : ['FP1']\n",
      "    Rejecting  epoch based on EEG : ['FP1']\n",
      "    Rejecting  epoch based on EEG : ['O1']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'CPz', 'FP2', 'F8', 'P4', 'P8', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'C3', 'C5', 'P3', 'P7', 'PO7', 'PO3', 'Pz', 'CPz', 'FP2', 'Fz', 'F4', 'F8', 'FC4', 'FCz', 'Cz', 'C4', 'C6', 'P4', 'P8', 'PO8', 'PO4', 'O2']\n",
      "    Rejecting  epoch based on EEG : ['P7', 'F8', 'P4', 'PO8', 'PO4']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'P4', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['PO3', 'F8', 'PO8', 'PO4']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EEG : ['FP2']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F4', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F4', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F4', 'F8', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F4', 'F8', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'FP2', 'F4', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'FP2', 'F4', 'F8', 'FC4']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1']\n",
      "    Rejecting  epoch based on EEG : ['FP1']\n",
      "    Rejecting  epoch based on EEG : ['O1']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EEG : ['FP2']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EOG : ['HEOG_right']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "running ICA ...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1.5 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.50\n",
      "- Lower transition bandwidth: 1.50 Hz (-6 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 565 samples (2.207 sec)\n",
      "\n",
      "Fitting ICA to data using 30 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Omitting 54470 of 119552 (45.56%) samples, retaining 65082 (54.44%) samples.\n",
      "Selecting by explained variance: 28 components\n",
      "Fitting ICA took 7.5s.\n",
      "excluded components: [0, 13, 17, 25, 2, 20, 24, 26, 27, 7, 9, 14, 15, 23]\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Need more than one channel to make topography for eeg. Disabling interactivity.\n",
      "Transforming to ICA space (28 components)\n",
      "Zeroing out 14 ICA components\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Need more than one channel to make topography for eeg. Disabling interactivity.\n",
      "<Info | 11 non-empty values\n",
      " bads: []\n",
      " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
      " chs: 30 EEG, 3 EOG\n",
      " custom_ref_applied: True\n",
      " dig: 33 items (3 Cardinal, 30 EEG)\n",
      " highpass: 0.4 Hz\n",
      " line_freq: 60\n",
      " lowpass: 54.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 33\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      " subject_info: 4 items (dict)\n",
      ">\n",
      "Transforming to ICA space (28 components)\n",
      "Zeroing out 14 ICA components\n",
      "Writing ICA solution to ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_events_chrei-ica.fif...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsource space\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pipeline\n",
    "\n",
    "load data\n",
    "read annotations\n",
    "resample to 256 Hz\n",
    "re-reference to P9 and P10\n",
    "(Extract a single channel and plot the whole timeseries)\n",
    "\"\"\"\n",
    "# path where to save the datasets.\n",
    "bids_root = \"../local/bids\"\n",
    "last_subject\n",
    "\n",
    "# time of peak\n",
    "peak_time_target_list = []\n",
    "peak_time_distractor_list = []\n",
    "peak_value_target_list = []\n",
    "peak_value_distractor_list = []\n",
    "\n",
    "for subject in range(first_subject, last_subject + 1):\n",
    "    print(\"subject =\", subject)\n",
    "    subject_id = f\"{subject:03}\"\n",
    "\n",
    "    bids_path = BIDSPath(\n",
    "        subject=subject_id,\n",
    "        task=\"P3\",\n",
    "        session=\"P3\",\n",
    "        datatype=\"eeg\",\n",
    "        suffix=\"eeg\",\n",
    "        root=bids_root,\n",
    "    )\n",
    "\n",
    "    # read the file\n",
    "    raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # fix the annotations readin\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path, raw)\n",
    "\n",
    "    # load data\n",
    "    raw.load_data()\n",
    "\n",
    "    # downsample frequency\n",
    "    downsample()\n",
    "\n",
    "    rereference()\n",
    "\n",
    "    # apply montage\n",
    "    apply_montage()\n",
    "\n",
    "    # band pass filtering between 0.4 and 54 hz\n",
    "    raw_f = band_pass_filtering(subject_id)\n",
    "\n",
    "    # plot each channel\n",
    "    #plot_each_channel(subject_id) # TODO turn back on\n",
    "    \n",
    "    # remove large muscle artifacts, extreme voltage offsets, or break periods\n",
    "    cleaning(raw_f, subject)\n",
    "\n",
    "    # ICA\n",
    "    raw_f = ICA(raw_f, subject)\n",
    "\n",
    "    \"\"\"\n",
    "    epochs, evts, evts_dict_stim = epoching()\n",
    "\n",
    "    (\n",
    "        peak_time_target_list,\n",
    "        peak_value_target_list,\n",
    "        peak_time_distractor_list,\n",
    "        peak_value_distractor_list,\n",
    "        target,\n",
    "        distractor\n",
    "    ) = erp_analysis()\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "inter-subject peak analysis\n",
    "\"\"\"\n",
    "\"\"\"# histograms\n",
    "(\n",
    "    average_time_difference,\n",
    "    meadian_time_difference,\n",
    "    std_dev_time_difference,\n",
    ") = erp_differences(\n",
    "    peak_time_target_list,\n",
    "    peak_time_distractor_list,\n",
    "    title=\"Delay of target ERP relative to distractor ERP\",\n",
    "    xlabel=\"relative delay in ms\",\n",
    ")\n",
    "print(\n",
    "    \"average_time_difference: \",\n",
    "    average_time_difference,\n",
    "    \"\\nmeadian_time_difference:\",\n",
    "    meadian_time_difference,\n",
    "    \"\\n std_dev_time_difference:\",\n",
    "    std_dev_time_difference,\n",
    ")\n",
    "\n",
    "(\n",
    "    average_value_difference,\n",
    "    meadian_value_difference,\n",
    "    std_dev_value_difference,\n",
    ") = erp_differences(\n",
    "    peak_value_target_list,\n",
    "    peak_value_distractor_list,\n",
    "    title=\"Delay of target ERP relative to distractor ERP\",\n",
    "    xlabel=\"relative delay in ms\",\n",
    ")\n",
    "print(\n",
    "    \"average_value_difference: \",\n",
    "    average_value_difference,\n",
    "    \"\\nmeadian_value_difference:\",\n",
    "    meadian_value_difference,\n",
    "    \"\\n std_dev_value_difference:\",\n",
    "    std_dev_value_difference,\n",
    ")\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "permutation tests\n",
    "\"\"\"\n",
    "# time delay of peak\n",
    "\"\"\"t_obs_time, p_values_time = permutation_test(\n",
    "    peak_time_target_list, peak_time_distractor_list\n",
    ")\"\"\"\n",
    "\n",
    "# difference in peak potential\n",
    "\"\"\"\n",
    "t_obs_value, p_values_value = permutation_test(\n",
    "    peak_value_target_list, peak_value_distractor_list\n",
    ")\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "source space\n",
    "\"\"\"\n",
    "#source_space_localization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
