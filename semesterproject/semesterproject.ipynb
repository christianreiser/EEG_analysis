{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "line of thinking\n",
    "documented motivation\n",
    "understand what er are doing\n",
    "\n",
    "\n",
    "proprocess 3 subjects and provide/document the cleaning times / bad channels, document the bad components\n",
    "\n",
    "- Preprocessing Filtering, re-referencening, ICA\n",
    "- Data cleaning: Time, channel and subjects\n",
    "- ERP peak analysis Extract the study-relevant ERP peak subjectwise (e.g. one value per subject) and statistically test them. RQ: On which ERP-peaks do we find major difference between the conditions?\n",
    "- Time Frequency analysis Calculate an induced time-frequency analysis of the main experimental contrast RQ: What oscillations underley our effect of interest?\n",
    "- either:\t- Mass Univariate Use a multiple regression of the main experimental contrast, controlling for reaction time (you need to calculate RT yourself). RQ: When/Where do we find differences between our conditions? Is there an influence of reaction time?\n",
    "\t\tOR\n",
    "\t\t- Decoding analysis Decode the main contrast of the experiment across time RQ: When is information about the conditions in our data available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary and Exploration\n",
    "P300: A visual oddball experiment with a prolonged effect at 300ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import libraries\n",
    "\"\"\"\n",
    "import mne\n",
    "import ccs_eeg_utils\n",
    "import mne  # read raw\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os  # make dir\n",
    "from config import *\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filtering(raw, subject_id):\n",
    "    \"\"\"\n",
    "    applys the firwin banpassfilter\n",
    "    \"\"\"\n",
    "    print(\"filtering ...\")\n",
    "\n",
    "    # plot raw data before band-pass filtering\n",
    "    raw.plot_psd(\n",
    "        area_mode=\"range\",\n",
    "        tmax=10.0,\n",
    "        average=False,\n",
    "        xscale=\"linear\",\n",
    "    )\n",
    "    ccs_eeg_utils.save_plot(\"01freq_before_filtering\", bids_path)\n",
    "\n",
    "    # apply filter\n",
    "    raw_f = raw.copy().filter(l_freq, h_freq, fir_design=fir_design)\n",
    "    raw_f.plot_psd(area_mode=\"range\", tmax=10.0, average=False, xscale=\"log\")\n",
    "    ccs_eeg_utils.save_plot(\"02freq_after_filtering\", bids_path)\n",
    "\n",
    "    raw.set_montage(\"standard_1020\", match_case=False)\n",
    "\n",
    "    return raw_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_channel(subject_id):\n",
    "    \"\"\"\n",
    "    plot data\n",
    "    \"\"\"\n",
    "    print(\"plotting each channel ...\")\n",
    "\n",
    "    # create dir to save plots if not existent\n",
    "    if not os.path.exists(str(str(bids_path)[:-37] + \"results/03whole_overlay/\")):\n",
    "        os.makedirs(str(str(bids_path)[:-37] + \"results/03whole_overlay/\"))\n",
    "\n",
    "    # Extract a single channel and plot the whole timeseries.\n",
    "    for channel_number in range(1, len(raw.ch_names)):  # 1\n",
    "\n",
    "        # show filtered -> low frequencies\n",
    "        fig = plt.figure()\n",
    "        a1 = fig.add_axes([0, 0, 1, 1])\n",
    "        a1.plot((raw[channel_number - 1][0].T))\n",
    "        a1.plot((raw_f[channel_number - 1][0].T))\n",
    "        a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "        plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "        plt.ylabel(\"potential [µV]\")\n",
    "        plt.xlabel(\"sample\")\n",
    "        # a1.set_xlim(0,25)\n",
    "        # a1.set_ylim(-0.00003,0.00003)\n",
    "        plt.savefig(\n",
    "            str(\n",
    "                str(bids_path)[:-37]\n",
    "                + \"results/03whole_overlay/channel\"\n",
    "                + str(channel_number)\n",
    "                + \".png\"\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        # plt.show()\n",
    "        plt.close(fig)  # don't display figure\n",
    "\n",
    "    # show raw -> high frequnecies\n",
    "    channel_number = 1\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0, 0, 1, 1])\n",
    "    a1.plot((raw[channel_number - 1][0].T))\n",
    "    a1.plot((raw_f[channel_number - 1][0].T))\n",
    "    a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "    plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "    plt.ylabel(\"potential [µV]\")\n",
    "    plt.xlabel(\"sample\")\n",
    "    a1.set_xlim(0, 25)\n",
    "    a1.set_ylim(0.0199, 0.01993)\n",
    "    ccs_eeg_utils.save_plot(\"04zoom_raw\", bids_path)\n",
    "    plt.close(fig)  # don't display figure\n",
    "\n",
    "    # show filtered -> high frequnecies are filtered\n",
    "    fig = plt.figure()\n",
    "    a1 = fig.add_axes([0, 0, 1, 1])\n",
    "    a1.plot((raw[channel_number - 1][0].T))\n",
    "    a1.plot((raw_f[channel_number - 1][0].T))\n",
    "    a1.legend([\"raw\", \"band-pass filtered\"])\n",
    "    plt.title(\"Subject: \" + str(subject_id) + \", channel: \" + str(channel_number))\n",
    "    plt.ylabel(\"potential [µV]\")\n",
    "    plt.xlabel(\"sample\")\n",
    "    a1.set_xlim(0, 25)\n",
    "    a1.set_ylim(-0.00003, 0.00003)\n",
    "    ccs_eeg_utils.save_plot(\"05zoom_filtered\", bids_path)\n",
    "    plt.close(fig)  # don't display figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(raw_f):\n",
    "    # clean manually\n",
    "    #%matplotlib qt\n",
    "    raw_f.plot(n_channels=len(raw_f.ch_names))\n",
    "\n",
    "    # get bad annotations\n",
    "    bad_ix = [i for i, a in enumerate(raw_f.annotations) if a[\"description\"] == \"BAD_\"]\n",
    "\n",
    "    # save bad annotations\n",
    "    raw_f.annotations[bad_ix].save(\n",
    "        str(str(bids_path)[:-37] + \"results/badannotations.csv\")\n",
    "    )\n",
    "\n",
    "    # read bad annotations\n",
    "    # annotations = mne.read_annotations(str(str(bids_path)[:-37] + \"results/badannotations.csv\"))\n",
    "\n",
    "    # append bad annotations\n",
    "    # raw_f.annotations.append(annotations.onset,annotations.duration,annotations.description)  # duplicates\n",
    "\n",
    "    # remove abd channels\n",
    "    raw_f.info[\"bads\"] = []\n",
    "\n",
    "    # intepolate bad channels\n",
    "    # raw_f.interpolate_bads()  # no bad channel found\n",
    "\n",
    "    # save cleaned data\n",
    "    raw.save(\n",
    "        str(str(bids_path)[:-37] + \"results/after_cleaning_raw.fif\"), overwrite=True\n",
    "    )\n",
    "\n",
    "    # load cleaned data\n",
    "    # raw_cleaned = mne.io.read_raw_fif(str(str(bids_path)[:-37] + \"results/after_cleaning_raw.fif\"))\n",
    "\n",
    "    \"\"\"TODO raw vs raw_f\"\"\"\n",
    "\n",
    "    # visualize effect of cleaning on ERP\n",
    "    evts, evts_dict = mne.events_from_annotations(raw)\n",
    "    wanted_keys = [e for e in evts_dict.keys() if \"stimulus\" in e]\n",
    "    evts_dict_stim = dict((k, evts_dict[k]) for k in wanted_keys if k in evts_dict)\n",
    "\n",
    "    # get epochs with and without rejection\n",
    "    epochs = mne.Epochs(\n",
    "        raw, evts, evts_dict_stim, tmin=-0.1, tmax=1, reject_by_annotation=False\n",
    "    )\n",
    "    epochs_manual = mne.Epochs(\n",
    "        raw, evts, evts_dict_stim, tmin=-0.1, tmax=1, reject_by_annotation=True\n",
    "    )\n",
    "    reject_criteria = dict(\n",
    "        eeg=200e-6, eog=200e-6  # 100 µV # HAD TO INCREASE IT HERE, 100 was too harsh\n",
    "    )  # 200 µV\n",
    "    epochs_thresh = mne.Epochs(\n",
    "        raw,\n",
    "        evts,\n",
    "        evts_dict_stim,\n",
    "        tmin=-0.1,\n",
    "        tmax=1,\n",
    "        reject=reject_criteria,\n",
    "        reject_by_annotation=False,\n",
    "    )\n",
    "\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # compare\n",
    "    # plt.plot([0,:])\n",
    "    mne.viz.plot_compare_evokeds(\n",
    "        {\n",
    "            \"raw\": epochs.average(),\n",
    "            \"clean\": epochs_manual.average(),\n",
    "            \"thresh\": epochs_thresh.average(),\n",
    "        },\n",
    "        picks=\"Cz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA(raw_f_f):\n",
    "    \"\"\"\n",
    "    ICA\n",
    "    \"\"\"\n",
    "    print(\"running ICA ...\")\n",
    "    raw_f_f.filter(l_freq_ica, h_freq_ica, fir_design=fir_design_ica)\n",
    "\n",
    "    # Generate an ICA object\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=0.9999999, random_state=93, method=ica_method, max_iter=200\n",
    "    )\n",
    "\n",
    "    # fit the ICA on the data\n",
    "    ica.fit(raw_f, verbose=True)\n",
    "\n",
    "    # plot components\n",
    "    ica.plot_components(picks=range(ica.n_components_ - 1))\n",
    "    ccs_eeg_utils.save_plot(\"06ICA_components\", bids_path)\n",
    "\n",
    "    # plot properties\n",
    "    # create dir to save plots if not existent\n",
    "\n",
    "    if not os.path.exists(str(str(bids_path)[:-37] + \"results/07ICA_properties/\")):\n",
    "        os.makedirs(str(str(bids_path)[:-37] + \"results/07ICA_properties/\"))\n",
    "    for component in range(ica.n_components_):\n",
    "        ica.plot_properties(\n",
    "            raw_f, picks=component, psd_args={\"fmax\": 35.0}, reject=None\n",
    "        )\n",
    "        # save plot\n",
    "        plt.savefig(\n",
    "            str(\n",
    "                str(bids_path)[:-37]\n",
    "                + \"results/07ICA_properties/component\"\n",
    "                + str(component)\n",
    "                + \".png\"\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        # don't display figure\n",
    "        plt.close()\n",
    "\n",
    "    \"\"\" TODO generalize for all subjects\"\"\"\n",
    "    \"\"\"\n",
    "    # Artefacts of subject one\n",
    "    heartbeat_artefacts = []\n",
    "    blink_artefacts = [3]\n",
    "    eye_artefacts = [0,1,2,6,24,29]\n",
    "    muscle_artefacts = [5,7,10,13,16,18,21,23,28,29] # often non-stationary activity, small ERPs, \"square-root spectrum\", one electrode?, Yaw, below/behind ear, lowwe back of the head, \n",
    "    noisy_electrodes = [] # single active electrode, small ERP, strong 50/60hz line noise\n",
    "    other_artefacts = []\n",
    "    # brain components ideally show strong and clear ERPs, activity stationary over whole experiment, powerspectrum including alpha/beta peak at ~10hz, \n",
    "    \"\"\"\n",
    "    # Artefacts of subject two\n",
    "    heartbeat_artefacts = []\n",
    "    blink_artefacts = [0]\n",
    "    eye_artefacts = []\n",
    "    muscle_artefacts = [\n",
    "        12,\n",
    "        19,\n",
    "        25,\n",
    "    ]  # often non-stationary activity, small ERPs, \"square-root spectrum\", one electrode?, Yaw, below/behind ear, lowwe back of the head,\n",
    "    noisy_electrodes = [\n",
    "        29\n",
    "    ]  # single active electrode, small ERP, strong 50/60hz line noise\n",
    "    other_artefacts = [3, 7, 8, 22, 23]\n",
    "    # brain components ideally show strong and clear ERPs, activity stationary over whole experiment, powerspectrum including alpha/beta peak at ~10hz,\n",
    "\n",
    "    exclude = []\n",
    "    exclude.extend(heartbeat_artefacts)\n",
    "    exclude.extend(blink_artefacts)\n",
    "    exclude.extend(eye_artefacts)\n",
    "    exclude.extend(muscle_artefacts)\n",
    "    exclude.extend(other_artefacts)\n",
    "    print(\"excluded components:\", exclude)\n",
    "    ica.exclude = exclude\n",
    "\n",
    "    # add events\n",
    "    evts, evts_dict_stim = add_events(raw_f)\n",
    "\n",
    "    # before ICA\n",
    "    epochs = mne.Epochs(\n",
    "        ica.get_sources(raw_f), evts, evts_dict_stim, tmin=-0.2, tmax=0.8\n",
    "    )\n",
    "    epochs.average(picks=picked_channel_num).plot()  # 13 for Pz?\n",
    "    ccs_eeg_utils.save_plot(\"08\" + str(picked_channel) + \"_before_ICA\", bids_path)\n",
    "\n",
    "    # after ICA\n",
    "    epochs = mne.Epochs(raw_f, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax)\n",
    "    epochs.average().plot(picks=picked_channel)\n",
    "    ccs_eeg_utils.save_plot(\"09\" + str(picked_channel) + \"_after_ICA\", bids_path)\n",
    "\n",
    "    # before / after overlay\n",
    "    reconst_raw_f = raw_f.copy()\n",
    "    ica.apply(reconst_raw_f, exclude=exclude)\n",
    "\n",
    "    # raw_f.plot()\n",
    "    # reconst_raw_f.plot()\n",
    "    ica.plot_overlay(raw_f, exclude=exclude)\n",
    "    ccs_eeg_utils.save_plot(\"10before_after_overlay\", bids_path)\n",
    "\n",
    "    # save ICA\n",
    "    ica.save(str(str(bids_path)[:-4] + \"_chrei-ica.fif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_events(raw):\n",
    "    \"\"\"\n",
    "    add events\n",
    "    \"\"\"\n",
    "    print(\"adding events ...\")\n",
    "    evts, evts_dict = mne.events_from_annotations(raw_f)\n",
    "\n",
    "    # get all keys which contain \"stimulus\"\n",
    "    wanted_keys = [\n",
    "        e for e in evts_dict.keys() if \"stimulus\" in e\n",
    "    ]  # subset the large event-dictionairy\n",
    "\n",
    "    evts_dict_stim = dict((k, evts_dict[k]) for k in wanted_keys if k in evts_dict)\n",
    "\n",
    "    return evts, evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching():\n",
    "    # Choosing Pz for P3 because this is the site most widely used in the literature and\n",
    "    # recommended by Kappenman et al.\n",
    "    # Cut the raw_f data to one channel using `raw_f.pick_channels([\"Pz\"])` -\n",
    "\n",
    "    evts, evts_dict_stim = add_events(raw_f)\n",
    "\n",
    "    raw_f.pick_channels([picked_channel])\n",
    "    print(raw_f)\n",
    "    plt.plot(raw_f[:, :][0].T)\n",
    "    ccs_eeg_utils.save_plot(\"11\" + str(picked_channel), bids_path)\n",
    "\n",
    "    raw_f.info\n",
    "\n",
    "    # These values reflect the values in the bids `*_events.tsv` file.\n",
    "    raw_f.annotations\n",
    "\n",
    "    # Epoch the data\n",
    "    epochs = mne.Epochs(\n",
    "        raw_f, evts, evts_dict_stim, tmin=epoch_tmin, tmax=epoch_tmax, baseline=baseline\n",
    "    )  # tmin and tmax chosen as recommended by Kappenman et al.\n",
    "\n",
    "    # Plot all trials\n",
    "    plt.plot(np.squeeze(epochs.get_data()[:, 0, :].T))\n",
    "    ccs_eeg_utils.save_plot(\"12trials\", bids_path)\n",
    "\n",
    "    return epochs, evts, evts_dict_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_value(data, timestamp):\n",
    "    \"\"\"\n",
    "    get peak values from timestamp\n",
    "    \"\"\"\n",
    "    peak_time_index = data.time_as_index(timestamp)\n",
    "    data_frame = data.to_data_frame(picks=picked_channel)\n",
    "    peak_value = data_frame.at[peak_time_index[0], picked_channel]\n",
    "\n",
    "    return peak_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_peak_data(target_peak, distractor_peak):\n",
    "    \"\"\"\n",
    "    create array where first column is the data and second column is the label\n",
    "    where: target -> 1, distractor -> 0\n",
    "\n",
    "    peak value | label\n",
    "    -----------|------\n",
    "    0.1234     | 1\n",
    "    0.2345     | 0\n",
    "    \"\"\"\n",
    "\n",
    "    # ini matrix with zeros\n",
    "    erp_data = np.zeros(((last_subject) * 2, 2))\n",
    "\n",
    "    # fill targets\n",
    "    for row in range(last_subject):\n",
    "        erp_data[row][0] = target_peak[row]  # values\n",
    "        erp_data[row][1] = 1  # labels\n",
    "\n",
    "    # fill distractors\n",
    "    for row in range(last_subject):\n",
    "        erp_data[row + last_subject][0] = distractor_peak[row]\n",
    "        # erp_data[row+last_subject][1] = 0 # already 0s\n",
    "\n",
    "    print(\"erp_data:\", erp_data)\n",
    "    print(\"erp_data.shape:\", erp_data.shape)\n",
    "\n",
    "    return erp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erp_analysis():\n",
    "    # indexing and averaging epochs\n",
    "    target = epochs[[\"stimulus:{}{}\".format(k, k) for k in [1, 2, 3, 4, 5]]].average()\n",
    "    distractor = epochs[\n",
    "        [\n",
    "            \"stimulus:{}{}\".format(k, j)\n",
    "            for k in [1, 2, 3, 4, 5]\n",
    "            for j in [1, 2, 3, 4, 5]\n",
    "            if k != j\n",
    "        ]\n",
    "    ].average()\n",
    "\n",
    "    # plotting\n",
    "    mne.viz.plot_compare_evokeds([target, distractor])\n",
    "    ccs_eeg_utils.save_plot(\"13epochs_average\", bids_path)\n",
    "\n",
    "    \"\"\"\n",
    "    get peaks\n",
    "    \"\"\"\n",
    "    # get peak times target\n",
    "    _, peak_time_target = target.get_peak(mode=\"pos\")  # get peak time\n",
    "    print(\"peak_time_target:\", peak_time_target)\n",
    "    peak_time_target_list.append(peak_time_target)\n",
    "\n",
    "    # get peak value target\n",
    "    peak_value_target = get_peak_value(target, peak_time_target)\n",
    "    print(\"peak_value_target:\", peak_value_target)\n",
    "    peak_value_target_list.append(peak_value_target)  # from epoch to evoked\n",
    "\n",
    "    # get peak times distractor\n",
    "    _, peak_time_distractor = distractor.get_peak(mode=\"pos\")\n",
    "    print(\"peak_time_distractor:\", peak_time_distractor)\n",
    "    peak_time_distractor_list.append(peak_time_distractor)\n",
    "\n",
    "    # get peak value distractor\n",
    "    peak_value_distractor = get_peak_value(distractor, peak_time_distractor)\n",
    "    print(\"peak_value_distractor:\", peak_value_distractor)\n",
    "    peak_value_distractor_list.append(peak_value_distractor)\n",
    "\n",
    "    # print(target_peak_t,distractor_peak_t)\n",
    "\n",
    "    return (\n",
    "        peak_time_target_list,\n",
    "        peak_value_target_list,\n",
    "        peak_time_distractor_list,\n",
    "        peak_value_distractor_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erp_differences(\n",
    "    peak_target_list,\n",
    "    peak_distractor_list,\n",
    "    title=\"title\",\n",
    "    xlabel=\"xlabel\",\n",
    "    ylabel=\"# subjects\",\n",
    "):\n",
    "    peak_difference_list = np.subtract(peak_target_list, peak_distractor_list)\n",
    "    #%matplotlib inline\n",
    "    _ = plt.hist(\n",
    "        peak_difference_list, bins=\"auto\"\n",
    "    )  # arguments are passed to np.histogram\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "    average_difference = np.average(peak_difference_list)\n",
    "    meadian_difference = np.median(peak_difference_list)\n",
    "    std_dev_difference = np.std(peak_difference_list)\n",
    "\n",
    "    # print(average_difference, meadian_difference, std_dev_difference)\n",
    "    return average_difference, meadian_difference, std_dev_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(peak_target, peak_distractor):\n",
    "    # create one data array with peak values and labels\n",
    "    peak_data = create_peak_data(peak_target, peak_distractor)\n",
    "\n",
    "    # perform permutation test\n",
    "    t_obs, p_values, H0 = mne.stats.permutation_t_test(peak_data, verbose=True)\n",
    "    # print('t_obs:', t_obs)\n",
    "    # print('p_values:', p_values)\n",
    "    # print('H0:', H0)\n",
    "\n",
    "    return t_obs, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject = 1\n",
      "Reading ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_eeg.fdt\n",
      "Reading events from ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_events.tsv.\n",
      "Reading channel info from ../local/bids/sub-001/ses-P3/eeg/sub-001_ses-P3_task-P3_channels.tsv.\n",
      "Reading 0 ... 478207  =      0.000 ...   466.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-269fec25a671>:34: RuntimeWarning: Data file name in EEG.data (sub-001_task-P3_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-P3_task-P3_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-13-269fec25a671>:34: RuntimeWarning: Did not find any coordsystem.json associated with sub-001_ses-P3_task-P3.\n",
      "\n",
      "The search_str was \"../local/bids/sub-001/**/sub-001_ses-P3*coordsystem.json\"\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "filtering ...\n",
      "Effective window size : 8.000 (s)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.4 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.40\n",
      "- Lower transition bandwidth: 0.40 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 2113 samples (8.254 sec)\n",
      "\n",
      "Effective window size : 8.000 (s)\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-001_ses-P3_task-P3_eeg.fdt, 1 x 119552 (467.0 s), ~965 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "peak_time_target: 0.42578125\n",
      "peak_value_target: 16.025469488369822\n",
      "peak_time_distractor: 0.2265625\n",
      "peak_value_distractor: 10.274463635692676\n",
      "subject = 2\n",
      "Reading ../local/bids/sub-002/ses-P3/eeg/sub-002_task-P3_eeg.fdt\n",
      "Reading events from ../local/bids/sub-002/ses-P3/eeg/sub-002_ses-P3_task-P3_events.tsv.\n",
      "Reading channel info from ../local/bids/sub-002/ses-P3/eeg/sub-002_ses-P3_task-P3_channels.tsv.\n",
      "Reading 0 ... 414719  =      0.000 ...   404.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-269fec25a671>:34: RuntimeWarning: Did not find any coordsystem.json associated with sub-002_ses-P3_task-P3.\n",
      "\n",
      "The search_str was \"../local/bids/sub-002/**/sub-002_ses-P3*coordsystem.json\"\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "filtering ...\n",
      "Effective window size : 8.000 (s)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.4 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.40\n",
      "- Lower transition bandwidth: 0.40 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 2113 samples (8.254 sec)\n",
      "\n",
      "Effective window size : 8.000 (s)\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-002_task-P3_eeg.fdt, 1 x 103680 (405.0 s), ~841 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "peak_time_target: 0.4296875\n",
      "peak_value_target: 38.99950711099559\n",
      "peak_time_distractor: 0.3828125\n",
      "peak_value_distractor: 18.104938127974933\n",
      "subject = 3\n",
      "Reading ../local/bids/sub-003/ses-P3/eeg/sub-003_ses-P3_task-P3_eeg.fdt\n",
      "Reading events from ../local/bids/sub-003/ses-P3/eeg/sub-003_ses-P3_task-P3_events.tsv.\n",
      "Reading channel info from ../local/bids/sub-003/ses-P3/eeg/sub-003_ses-P3_task-P3_channels.tsv.\n",
      "Reading 0 ... 386047  =      0.000 ...   376.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-269fec25a671>:34: RuntimeWarning: Data file name in EEG.data (sub-003_task-P3_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-003_ses-P3_task-P3_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-13-269fec25a671>:34: RuntimeWarning: Did not find any coordsystem.json associated with sub-003_ses-P3_task-P3.\n",
      "\n",
      "The search_str was \"../local/bids/sub-003/**/sub-003_ses-P3*coordsystem.json\"\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom EEG reference.\n",
      "filtering ...\n",
      "Effective window size : 8.000 (s)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.4 - 54 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.40\n",
      "- Lower transition bandwidth: 0.40 Hz (-6 dB cutoff frequency: 0.20 Hz)\n",
      "- Upper passband edge: 54.00 Hz\n",
      "- Upper transition bandwidth: 13.50 Hz (-6 dB cutoff frequency: 60.75 Hz)\n",
      "- Filter length: 2113 samples (8.254 sec)\n",
      "\n",
      "Effective window size : 8.000 (s)\n",
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-003_ses-P3_task-P3_eeg.fdt, 1 x 96512 (377.0 s), ~785 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "peak_time_target: 0.50390625\n",
      "peak_value_target: 26.564137034345023\n",
      "peak_time_distractor: 0.51953125\n",
      "peak_value_distractor: 16.0594330643477\n",
      "average_time_difference:  0.07682291666666667 \n",
      "meadian_time_difference: 0.046875 \n",
      " std_dev_time_difference: 0.0902297715576584\n",
      "average_value_difference:  12.38342626856504 \n",
      "meadian_value_difference: 10.504703969997323 \n",
      " std_dev_value_difference: 6.323452336449686\n",
      "erp_data: [[0.42578125 1.        ]\n",
      " [0.4296875  1.        ]\n",
      " [0.50390625 1.        ]\n",
      " [0.2265625  0.        ]\n",
      " [0.3828125  0.        ]\n",
      " [0.51953125 0.        ]]\n",
      "erp_data.shape: (6, 2)\n",
      "Permuting 31 times (exact test)...\n",
      "erp_data: [[16.02546949  1.        ]\n",
      " [38.99950711  1.        ]\n",
      " [26.56413703  1.        ]\n",
      " [10.27446364  0.        ]\n",
      " [18.10493813  0.        ]\n",
      " [16.05943306  0.        ]]\n",
      "erp_data.shape: (6, 2)\n",
      "Permuting 31 times (exact test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1a38f678f62e>:16: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pipeline\n",
    "\n",
    "load data\n",
    "read annotations\n",
    "resample to 256 Hz\n",
    "re-reference to P9 and P10\n",
    "(Extract a single channel and plot the whole timeseries)\n",
    "\"\"\"\n",
    "# path where to save the datasets.\n",
    "bids_root = \"../local/bids\"\n",
    "last_subject\n",
    "\n",
    "# time of peak\n",
    "peak_time_target_list = []\n",
    "peak_time_distractor_list = []\n",
    "peak_value_target_list = []\n",
    "peak_value_distractor_list = []\n",
    "\n",
    "for subject in range(frist_subject, last_subject + 1):\n",
    "    print(\"subject =\", subject)\n",
    "    subject_id = f\"{subject:03}\"\n",
    "\n",
    "    bids_path = BIDSPath(\n",
    "        subject=subject_id,\n",
    "        task=\"P3\",\n",
    "        session=\"P3\",\n",
    "        datatype=\"eeg\",\n",
    "        suffix=\"eeg\",\n",
    "        root=bids_root,\n",
    "    )\n",
    "\n",
    "    # read the file\n",
    "    raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # fix the annotations readin\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path, raw)\n",
    "\n",
    "    # load data\n",
    "    raw.load_data()\n",
    "\n",
    "    # delay shift\n",
    "    # todo\n",
    "\n",
    "    # resample / downsample frequency\n",
    "    raw.resample(\n",
    "        sfreq, npad=\"auto\"\n",
    "    )  # set sampling frequency to 256 Hz as in Kappenman et al.\n",
    "\n",
    "    # rerefernecing to P9 and P10 becuase Kappenman et al. says\n",
    "    # \"we find that P9 and P10 provide cleaner signals than the traditional mastoid sites\"\n",
    "    raw.set_eeg_reference(ref_channels=ref_channels, verbose=None)\n",
    "\n",
    "    # add channel locations\n",
    "    raw.set_montage(\"standard_1020\", match_case=False)\n",
    "\n",
    "    # band pass filtering between 0.1 and 54 hz\n",
    "    raw_f = band_pass_filtering(raw, subject_id)\n",
    "\n",
    "    # plot each channel\n",
    "    # plot_each_channel(subject_id) # takes a while\n",
    "\n",
    "    # remove large muscle artifacts, extreme voltage offsets, or break periods\n",
    "    # cleaning(raw_f)\n",
    "\n",
    "    # ICA\n",
    "    # ICA(raw_f)\n",
    "\n",
    "    epochs, evts, evts_dict_stim = epoching()\n",
    "\n",
    "    (\n",
    "        peak_time_target_list,\n",
    "        peak_value_target_list,\n",
    "        peak_time_distractor_list,\n",
    "        peak_value_distractor_list,\n",
    "    ) = erp_analysis()\n",
    "\n",
    "# histograms\n",
    "(\n",
    "    average_time_difference,\n",
    "    meadian_time_difference,\n",
    "    std_dev_time_difference,\n",
    ") = erp_differences(\n",
    "    peak_time_target_list,\n",
    "    peak_time_distractor_list,\n",
    "    title=\"Delay of target ERP relative to distractor ERP\",\n",
    "    xlabel=\"relative delay in ms\",\n",
    ")\n",
    "print(\n",
    "    \"average_time_difference: \",\n",
    "    average_time_difference,\n",
    "    \"\\nmeadian_time_difference:\",\n",
    "    meadian_time_difference,\n",
    "    \"\\n std_dev_time_difference:\",\n",
    "    std_dev_time_difference,\n",
    ")\n",
    "\n",
    "(\n",
    "    average_value_difference,\n",
    "    meadian_value_difference,\n",
    "    std_dev_value_difference,\n",
    ") = erp_differences(\n",
    "    peak_value_target_list,\n",
    "    peak_value_distractor_list,\n",
    "    title=\"Delay of target ERP relative to distractor ERP\",\n",
    "    xlabel=\"relative delay in ms\",\n",
    ")\n",
    "print(\n",
    "    \"average_value_difference: \",\n",
    "    average_value_difference,\n",
    "    \"\\nmeadian_value_difference:\",\n",
    "    meadian_value_difference,\n",
    "    \"\\n std_dev_value_difference:\",\n",
    "    std_dev_value_difference,\n",
    ")\n",
    "\n",
    "# permutation tests\n",
    "t_obs_time, p_values_time = permutation_test(\n",
    "    peak_time_target_list, peak_time_distractor_list\n",
    ")\n",
    "t_obs_value, p_values_value = permutation_test(\n",
    "    peak_value_target_list, peak_value_distractor_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 11 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
       " chs: 30 EEG, 3 EOG\n",
       " custom_ref_applied: True\n",
       " dig: 33 items (3 Cardinal, 30 EEG)\n",
       " highpass: 0.0 Hz\n",
       " line_freq: 60\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 33\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 4 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 11 non-empty values\n",
       " bads: []\n",
       " ch_names: Pz\n",
       " chs: 1 EEG\n",
       " custom_ref_applied: True\n",
       " dig: 33 items (3 Cardinal, 30 EEG)\n",
       " highpass: 0.4 Hz\n",
       " line_freq: 60\n",
       " lowpass: 54.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 1\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 4 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_f.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding events ...\n",
      "Used Annotations descriptions: ['response:201', 'response:202', 'stimulus:11', 'stimulus:12', 'stimulus:13', 'stimulus:14', 'stimulus:15', 'stimulus:21', 'stimulus:22', 'stimulus:23', 'stimulus:24', 'stimulus:25', 'stimulus:31', 'stimulus:32', 'stimulus:33', 'stimulus:34', 'stimulus:35', 'stimulus:41', 'stimulus:42', 'stimulus:43', 'stimulus:44', 'stimulus:45', 'stimulus:51', 'stimulus:52', 'stimulus:53', 'stimulus:54', 'stimulus:55']\n",
      "<RawEEGLAB | sub-003_ses-P3_task-P3_eeg.fdt, 1 x 96512 (377.0 s), ~785 kB, data loaded>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs, evts, evts_dict_stim = epoching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# ensure all conditions have the same counts, as the ANOVA expects a fully balanced data matrix and \\n# does not forgive imbalances that generously (risk of type-I error).\\nepochs.equalize_event_counts(evts_dict_stim) # TODO not sure if it's good that 100 epoches are droped\\n\\n# Factor to down-sample the temporal dimension of the TFR computed by\\n# tfr_morlet.\\ndecim = 2\\nfrequencies = np.arange(7, 30, 3)  # define frequencies of interest\\nn_cycles = frequencies / frequencies[0]\\nzero_mean = False  # don't correct morlet wavelet to be of mean zero\\n# To have a true wavelet zero_mean should be True but here for illustration\\n# purposes it helps to spot the evoked response.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# ensure all conditions have the same counts, as the ANOVA expects a fully balanced data matrix and \n",
    "# does not forgive imbalances that generously (risk of type-I error).\n",
    "epochs.equalize_event_counts(evts_dict_stim) # TODO not sure if it's good that 100 epoches are droped\n",
    "\n",
    "# Factor to down-sample the temporal dimension of the TFR computed by\n",
    "# tfr_morlet.\n",
    "decim = 2\n",
    "frequencies = np.arange(7, 30, 3)  # define frequencies of interest\n",
    "n_cycles = frequencies / frequencies[0]\n",
    "zero_mean = False  # don't correct morlet wavelet to be of mean zero\n",
    "# To have a true wavelet zero_mean should be True but here for illustration\n",
    "# purposes it helps to spot the evoked response.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from mne.time_frequency import tfr_morlet'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from mne.time_frequency import tfr_morlet\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimport mne\\nfrom mne.time_frequency import tfr_morlet\\nfrom mne.stats import f_threshold_mway_rm, f_mway_rm, fdr_correction\\nfrom mne.datasets import sample'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.stats import f_threshold_mway_rm, f_mway_rm, fdr_correction\n",
    "from mne.datasets import sample\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create TFR (time-frequency representations) for all conditions\\nepochs_power = list()\\nfor condition in [epochs[k] for k in evts_dict_stim]:\\n    this_tfr = tfr_morlet(condition, frequencies, n_cycles=n_cycles,\\n                          decim=decim, average=False, zero_mean=zero_mean,\\n                          return_itc=False)\\n    this_tfr.apply_baseline(mode='ratio', baseline=(None, 0))\\n    this_power = this_tfr.data[:, 0, :, :]  # we only have one channel.\\n    epochs_power.append(this_power)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create TFR (time-frequency representations) for all conditions\n",
    "epochs_power = list()\n",
    "for condition in [epochs[k] for k in evts_dict_stim]:\n",
    "    this_tfr = tfr_morlet(condition, frequencies, n_cycles=n_cycles,\n",
    "                          decim=decim, average=False, zero_mean=zero_mean,\n",
    "                          return_itc=False)\n",
    "    this_tfr.apply_baseline(mode='ratio', baseline=(None, 0))\n",
    "    this_power = this_tfr.data[:, 0, :, :]  # we only have one channel.\n",
    "    epochs_power.append(this_power)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Setup repeated measures ANOVA\\n# We will tell the ANOVA how to interpret the data matrix in terms of factors. \\n# This is done via the factor levels argument which is a list of the number factor levels for each factor.\\nn_conditions = len(epochs.event_id)\\nn_replications = int(epochs.events.shape[0] / n_conditions)\\n\\nfactor_levels = [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]  # number of levels in each factor\\neffects = 'A*B'  # this is the default signature for computing all effects\\n# Other possible options are 'A' or 'B' for the corresponding main effects\\n# or 'A:B' for the interaction effect only (this notation is borrowed from the\\n# R formula language)\\nn_frequencies = len(frequencies)\\ntimes = 1e3 * epochs.times[::decim]\\nn_times = len(times)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Setup repeated measures ANOVA\n",
    "# We will tell the ANOVA how to interpret the data matrix in terms of factors. \n",
    "# This is done via the factor levels argument which is a list of the number factor levels for each factor.\n",
    "n_conditions = len(epochs.event_id)\n",
    "n_replications = int(epochs.events.shape[0] / n_conditions)\n",
    "\n",
    "factor_levels = [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]  # number of levels in each factor\n",
    "effects = 'A*B'  # this is the default signature for computing all effects\n",
    "# Other possible options are 'A' or 'B' for the corresponding main effects\n",
    "# or 'A:B' for the interaction effect only (this notation is borrowed from the\n",
    "# R formula language)\n",
    "n_frequencies = len(frequencies)\n",
    "times = 1e3 * epochs.times[::decim]\n",
    "n_times = len(times)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Now we’ll assemble the data matrix and swap axes so the trial replications are the first dimension and the conditions are the second dimension.\\n\\ndata = np.swapaxes(np.asarray(epochs_power), 1, 0)\\n# reshape last two dimensions in one mass-univariate observation-vector\\ndata = data.reshape(n_replications, n_conditions, n_frequencies * n_times)\\n\\n# so we have replications * conditions * observations:\\nprint(data.shape)\\nprint(n_conditions)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Now we’ll assemble the data matrix and swap axes so the trial replications are the first dimension and the conditions are the second dimension.\n",
    "\n",
    "data = np.swapaxes(np.asarray(epochs_power), 1, 0)\n",
    "# reshape last two dimensions in one mass-univariate observation-vector\n",
    "data = data.reshape(n_replications, n_conditions, n_frequencies * n_times)\n",
    "\n",
    "# so we have replications * conditions * observations:\n",
    "print(data.shape)\n",
    "print(n_conditions)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Now we’re ready to run our repeated measures ANOVA.\\n\\n# Note. As we treat trials as subjects, the test only accounts for time locked responses,\\n# despite the ‘induced’ approach. For analysis for induced power at the group level averaged TRFs are required.\\nprint(\\'f_mway_rm\\')\\nfvals, pvals = f_mway_rm(data, factor_levels, effects=effects)\\n\\neffect_labels = [\\'modality\\', \\'location\\', \\'modality by location\\']\\n\\n# let\\'s visualize our effects by computing f-images\\nfor effect, sig, effect_label in zip(fvals, pvals, effect_labels):\\n    print(\\'for\\')\\n    plt.figure()\\n    # show naive F-values in gray\\n    plt.imshow(effect.reshape(8, 211), cmap=plt.cm.gray, extent=[times[0],\\n               times[-1], frequencies[0], frequencies[-1]], aspect=\\'auto\\',\\n               origin=\\'lower\\')\\n    # create mask for significant Time-frequency locations\\n    effect = np.ma.masked_array(effect, [sig > .05])\\n    plt.imshow(effect.reshape(8, 211), cmap=\\'RdBu_r\\', extent=[times[0],\\n               times[-1], frequencies[0], frequencies[-1]], aspect=\\'auto\\',\\n               origin=\\'lower\\')\\n    plt.colorbar()\\n    plt.xlabel(\\'Time (ms)\\')\\n    plt.ylabel(\\'Frequency (Hz)\\')\\n    plt.title(r\"Time-locked response for \\'%s\\' (%s)\" % (effect_label, ch_name))\\n    plt.show()'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Now we’re ready to run our repeated measures ANOVA.\n",
    "\n",
    "# Note. As we treat trials as subjects, the test only accounts for time locked responses,\n",
    "# despite the ‘induced’ approach. For analysis for induced power at the group level averaged TRFs are required.\n",
    "print('f_mway_rm')\n",
    "fvals, pvals = f_mway_rm(data, factor_levels, effects=effects)\n",
    "\n",
    "effect_labels = ['modality', 'location', 'modality by location']\n",
    "\n",
    "# let's visualize our effects by computing f-images\n",
    "for effect, sig, effect_label in zip(fvals, pvals, effect_labels):\n",
    "    print('for')\n",
    "    plt.figure()\n",
    "    # show naive F-values in gray\n",
    "    plt.imshow(effect.reshape(8, 211), cmap=plt.cm.gray, extent=[times[0],\n",
    "               times[-1], frequencies[0], frequencies[-1]], aspect='auto',\n",
    "               origin='lower')\n",
    "    # create mask for significant Time-frequency locations\n",
    "    effect = np.ma.masked_array(effect, [sig > .05])\n",
    "    plt.imshow(effect.reshape(8, 211), cmap='RdBu_r', extent=[times[0],\n",
    "               times[-1], frequencies[0], frequencies[-1]], aspect='auto',\n",
    "               origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title(r\"Time-locked response for '%s' (%s)\" % (effect_label, ch_name))\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexercise 3 but is it necessary?\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "exercise 3 but is it necessary?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
